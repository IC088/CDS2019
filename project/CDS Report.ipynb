{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_UzOWRQkKNfG"
   },
   "source": [
    "**CDS REPORT**\n",
    "\n",
    "Notebook for data training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3766,
     "status": "ok",
     "timestamp": 1574999244112,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "Mklqu9yLGt3A",
    "outputId": "9f9442fa-8c4a-492a-b717-f57286151d1f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_dir_image = '/content/gdrive/My Drive/Colab Notebooks/Flicker8k_Dataset'\n",
    "root_dir_text = '/content/gdrive/My Drive/Colab Notebooks/Text_Files'\n",
    "root_captioning = 'C:/Users/Asus/Documents/GitHub/CDS2019/project'\n",
    "# print('Note: using Google CoLab')\n",
    "# COLAB = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPHSA-PXHfTt"
   },
   "source": [
    "Here, InceptionV3 is used in order to extract the features of the images from the flickr 8k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5296,
     "status": "ok",
     "timestamp": 1574999245654,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "BPnpQCMMG9y7",
    "outputId": "2ca45961-b69c-4d1d-e28f-ded223c10ee3"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import tensorflow.keras.applications.mobilenet  \n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import tensorflow.keras.applications.inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DS-8bbMFLrsA"
   },
   "source": [
    "Importing the necessary libraries for data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4FgLhNJHNbH"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow.keras.preprocessing.image\n",
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTpKkKBuKwJb"
   },
   "outputs": [],
   "source": [
    "START = \"startseq\"\n",
    "STOP = \"endseq\"\n",
    "EPOCHS = 10\n",
    "USE_INCEPTION = True\n",
    "USE_VGG16 = True\n",
    "USE_Resnet50 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcPPEpYiK4yJ"
   },
   "outputs": [],
   "source": [
    "def clean_caption_text():\n",
    "  null_punct = str.maketrans('', '', string.punctuation)\n",
    "  lookup = dict()\n",
    "  with open( os.path.join(root_captioning,'Text_Files','Flickr8k.token.txt'), 'r') as fp:\n",
    "    max_length = 0\n",
    "    for line in fp.read().split('\\n'):\n",
    "      tok = line.split()\n",
    "      if len(line) >= 2:\n",
    "        id = tok[0].split('.')[0]\n",
    "        desc = tok[1:]\n",
    "        \n",
    "        # Cleanup description\n",
    "        desc = [word.lower() for word in desc]\n",
    "        desc = [w.translate(null_punct) for w in desc]\n",
    "        desc = [word for word in desc if len(word)>1]\n",
    "        desc = [word for word in desc if word.isalpha()]\n",
    "        max_length = max(max_length,len(desc))\n",
    "        \n",
    "        if id not in lookup:\n",
    "          lookup[id] = list()\n",
    "        lookup[id].append(' '.join(desc))\n",
    "        \n",
    "  lex = set()\n",
    "  for key in lookup:\n",
    "    [lex.update(d.split()) for d in lookup[key]]\n",
    "\n",
    "  return lookup, lex, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhG02d4EOELD"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Asus/Documents/GitHub/CDS2019/project\\\\Text_Files\\\\Flickr8k.token.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bb4def914a97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlookup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_caption_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-fb2db0bab754>\u001b[0m in \u001b[0;36mclean_caption_text\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mnull_punct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mlookup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_captioning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Text_Files'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Flickr8k.token.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Asus/Documents/GitHub/CDS2019/project\\\\Text_Files\\\\Flickr8k.token.txt'"
     ]
    }
   ],
   "source": [
    "lookup, lex, max_length = clean_caption_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6289,
     "status": "ok",
     "timestamp": 1574999246690,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "7XqwujpOOAFZ",
    "outputId": "2b1a9dbf-e2ad-4f64-b937-afabec30a2f6"
   },
   "outputs": [],
   "source": [
    "print('Sanity check for the dataset to make sure they are cleaned properly\\n')\n",
    "\n",
    "print(f'The number of unique words in the dataset: {len(lookup)}')\n",
    "print(f'The length of dictionary: {len(lex)}') \n",
    "print(f'The maximum length of a caption: {max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6282,
     "status": "ok",
     "timestamp": 1574999246694,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "LfDIjcYJOSn2",
    "outputId": "155125b2-021f-44ee-8d96-fb7f22d9a267"
   },
   "outputs": [],
   "source": [
    "img = glob.glob(os.path.join(root_captioning,'Flicker8k_Dataset', '*.jpg'))\n",
    "print(f'Number of images in the dataset: {len(img)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6273,
     "status": "ok",
     "timestamp": 1574999246696,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "M1Nz8H9uQBnK",
    "outputId": "a09042f5-d1a3-47df-f3dd-cad27cf434c4"
   },
   "outputs": [],
   "source": [
    "print('Loading test and train captions\\n')\n",
    "train_images_path = os.path.join(root_captioning,'Text_Files','Flickr_8k.trainImages.txt') \n",
    "train_images = set(open(train_images_path, 'r').read().strip().split('\\n'))\n",
    "test_images_path = os.path.join(root_captioning,'Text_Files','Flickr_8k.testImages.txt') \n",
    "test_images = set(open(test_images_path, 'r').read().strip().split('\\n'))\n",
    "\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "for i in img:\n",
    "  f = os.path.split(i)[-1]\n",
    "  if f in train_images: \n",
    "    train_img.append(f) \n",
    "  elif f in test_images:\n",
    "    test_img.append(f)\n",
    "print(f'Training Captions: {train_img}')\n",
    "print(f'Testing Captions: {test_img}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6258,
     "status": "ok",
     "timestamp": 1574999246697,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "CfcYnsNRQUxO",
    "outputId": "7f58ac68-d2d6-4ac5-9a49-ae55840473e0"
   },
   "outputs": [],
   "source": [
    "print('Start building caption sequences')\n",
    "\n",
    "train_descriptions = {k:v for k,v in lookup.items() if f'{k}.jpg' in train_images}\n",
    "for n,v in train_descriptions.items(): \n",
    "  for d in range(len(v)):\n",
    "    v[d] = f'{START} {v[d]} {STOP}'\n",
    "print(f'The Sequences are: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DF2Z3dqaSB0m"
   },
   "outputs": [],
   "source": [
    "if USE_INCEPTION:\n",
    "  encode_model = InceptionV3(weights='imagenet')\n",
    "  encode_model = Model(encode_model.input, encode_model.layers[-2].output)\n",
    "  WIDTH = 299\n",
    "  HEIGHT = 299\n",
    "  OUTPUT_DIM = 2048\n",
    "  preprocess_input = tensorflow.keras.applications.inception_v3.preprocess_input\n",
    "else:\n",
    "  # encode_model = MobileNet(weights='imagenet',include_top=False)\n",
    "  # WIDTH = 224\n",
    "  # HEIGHT = 224\n",
    "  # OUTPUT_DIM = 50176\n",
    "  # preprocess_input = tensorflow.keras.applications.mobilenet.preprocess_input\n",
    "  print('Check with VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12582,
     "status": "ok",
     "timestamp": 1574999253041,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "uN1EbqtWVeis",
    "outputId": "e6ae1eb3-225e-4396-a1e7-4d0a64e42cbd"
   },
   "outputs": [],
   "source": [
    "encode_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tc2dxSPbVi-0"
   },
   "outputs": [],
   "source": [
    "def encodeImage(img):\n",
    "  # Resize all images to a standard size (specified bythe image encoding network)\n",
    "  img = img.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
    "  # Convert a PIL image to a numpy array\n",
    "  x = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
    "  # Expand to 2D array\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  # Perform any preprocessing needed by InceptionV3 or others\n",
    "  x = preprocess_input(x)\n",
    "  # Call InceptionV3 (or other) to extract the smaller feature set for the image.\n",
    "  x = encode_model.predict(x) # Get the encoding vector for the image\n",
    "  # Shape to correct form to be accepted by LSTM captioning network.\n",
    "  x = np.reshape(x, OUTPUT_DIM )\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12565,
     "status": "ok",
     "timestamp": 1574999253047,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "OJw-9yrDL0AD",
    "outputId": "cd49e9ed-d9cb-4c62-c609-ec1a6124b895"
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(root_captioning,f'train{OUTPUT_DIM}.pkl')\n",
    "print(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZuZ2Y7qVqF5"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(train_path):\n",
    "  start = time()\n",
    "  encoding_train = {}\n",
    "  for id in tqdm(train_img):\n",
    "    image_path = os.path.join(root_captioning,'Flicker8k_Dataset', id)\n",
    "    img = tensorflow.keras.preprocessing.image.load_img(image_path, target_size=(HEIGHT, WIDTH))\n",
    "    encoding_train[id] = encodeImage(img)\n",
    "  with open(train_path, \"wb+\") as fp:\n",
    "    pickle.dump(encoding_train, fp)\n",
    "  # print(f\"\\nGenerating training set took: {hms_string(time()-start)}\")\n",
    "else:\n",
    "  with open(train_path, \"rb+\") as fp:\n",
    "    encoding_train = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ysjmKY48g3Az"
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(root_captioning,f'test{OUTPUT_DIM}.pkl')\n",
    "if not os.path.exists(test_path):\n",
    "  start = time()\n",
    "  encoding_test = {}\n",
    "  for id in tqdm(test_img):\n",
    "    image_path = os.path.join(root_captioning,'Flicker8k_Dataset', id)\n",
    "    img = tensorflow.keras.preprocessing.image.load_img(image_path, target_size=(HEIGHT, WIDTH))\n",
    "    encoding_test[id] = encodeImage(img)\n",
    "  with open(test_path, \"wb\") as fp:\n",
    "    pickle.dump(encoding_test, fp)\n",
    "  # print(f\"\\nGenerating testing set took: {hms_string(time()-start)}\")\n",
    "else:\n",
    "  with open(test_path, \"rb\") as fp:\n",
    "    encoding_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12883,
     "status": "ok",
     "timestamp": 1574999253389,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "UgPlS4FPiU6c",
    "outputId": "19ad9d31-d3f2-49c9-c7ad-2a892d79a0c0"
   },
   "outputs": [],
   "source": [
    "all_train_captions = []\n",
    "for key, val in train_descriptions.items():\n",
    "    for cap in val:\n",
    "        all_train_captions.append(cap)\n",
    "print(len(all_train_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12877,
     "status": "ok",
     "timestamp": 1574999253390,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "6ySCQ7tMKs2k",
    "outputId": "690b8278-cecb-4b46-acf4-5016bbb13e8f"
   },
   "outputs": [],
   "source": [
    "word_count_threshold = 15\n",
    "word_counts = {}\n",
    "nsents = 0\n",
    "for sent in all_train_captions:\n",
    "    nsents += 1\n",
    "    for w in sent.split(' '):\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "print('preprocessed words %d ==> %d' % (len(word_counts), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12870,
     "status": "ok",
     "timestamp": 1574999253391,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "cPdg9iIijLbZ",
    "outputId": "973250ed-480f-4d77-a13f-f9261a323e59"
   },
   "outputs": [],
   "source": [
    "idxtoword = {}\n",
    "wordtoidx = {}\n",
    "\n",
    "ix = 1\n",
    "for w in vocab:\n",
    "    wordtoidx[w] = ix\n",
    "    idxtoword[ix] = w\n",
    "    ix += 1\n",
    "    \n",
    "vocab_size = len(idxtoword) + 1 \n",
    "print(vocab_size)\n",
    "max_length +=2\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9AHORLojb-g"
   },
   "source": [
    "DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QClZI4y1jRRf"
   },
   "outputs": [],
   "source": [
    "def data_generator(descriptions, photos, wordtoidx, max_length, num_photos_per_batch):\n",
    "  # x1 - Training data for photos\n",
    "  # x2 - The caption that goes with each photo\n",
    "  # y - The predicted rest of the caption\n",
    "  x1, x2, y = [], [], []\n",
    "  n=0\n",
    "  while True:\n",
    "    for key, desc_list in descriptions.items():\n",
    "      n+=1\n",
    "      photo = photos[key+'.jpg']\n",
    "      # Each photo has 5 descriptions\n",
    "      for desc in desc_list:\n",
    "        # Convert each word into a list of sequences.\n",
    "        seq = [wordtoidx[word] for word in desc.split(' ') if word in wordtoidx]\n",
    "        # Generate a training case for every possible sequence and outcome\n",
    "        for i in range(1, len(seq)):\n",
    "          in_seq, out_seq = seq[:i], seq[i]\n",
    "          in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "          out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "          x1.append(photo)\n",
    "          x2.append(in_seq)\n",
    "          y.append(out_seq)\n",
    "      if n==num_photos_per_batch:\n",
    "        yield ([np.array(x1), np.array(x2)], np.array(y))\n",
    "        x1, x2, y = [], [], []\n",
    "        n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17582,
     "status": "ok",
     "timestamp": 1574999258117,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "H5SiAApZjefz",
    "outputId": "41509280-7178-4ba9-cbcf-d4a86f198e83"
   },
   "outputs": [],
   "source": [
    "glove_dir = os.path.join(root_captioning,'glob.6B')\n",
    "embeddings_index = {} \n",
    "f = open(os.path.join(glove_dir, 'glove.840B.300d.txt'), encoding=\"utf-8\")\n",
    "try:\n",
    "  for line in tqdm(f):\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "except ValueError:\n",
    "  pass\n",
    "\n",
    "f.close()\n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17576,
     "status": "ok",
     "timestamp": 1574999258119,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "9kMlzWc_jt0j",
    "outputId": "dded3d04-6903-4122-b7d3-76f9c61e0535"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in wordtoidx.items():\n",
    "    #if i < max_words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in the embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCq4OAWoopWC"
   },
   "outputs": [],
   "source": [
    "inputs1 = Input(shape=(OUTPUT_DIM,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "caption_model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19350,
     "status": "ok",
     "timestamp": 1574999259906,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "lXP6Juf_o9el",
    "outputId": "efd409fe-b98c-4dcb-a7e1-c1c7b6417254"
   },
   "outputs": [],
   "source": [
    "caption_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJQZhuAVpICa"
   },
   "outputs": [],
   "source": [
    "caption_model.layers[2].set_weights([embedding_matrix])\n",
    "caption_model.layers[2].trainable = False\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IIEXkqtpYUY"
   },
   "outputs": [],
   "source": [
    "number_pics_per_bath = 3\n",
    "steps = len(train_descriptions)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19334,
     "status": "ok",
     "timestamp": 1574999259910,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "BBr89ffcrH64",
    "outputId": "e395823c-b1ba-45bb-ed25-71ed0c62142c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(caption_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svfHft2wrCWJ"
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(root_captioning,f'caption-model15-300.hdf5')\n",
    "if not os.path.exists(model_path):\n",
    "  for i in tqdm(range(EPOCHS*2)):\n",
    "      generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
    "      caption_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "\n",
    "  caption_model.optimizer.lr = 1e-4\n",
    "  number_pics_per_bath = 6\n",
    "  steps = len(train_descriptions)//number_pics_per_bath\n",
    "\n",
    "  for i in range(EPOCHS):\n",
    "      generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
    "      caption_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)  \n",
    "  caption_model.save_weights(model_path)\n",
    "  # print(f\"\\Training took: {hms_string(time()-start)}\")\n",
    "else:\n",
    "  caption_model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAnSEoSJvtNP"
   },
   "outputs": [],
   "source": [
    "def generateCaption(photo):\n",
    "    in_text = START\n",
    "    for i in range(max_length):\n",
    "        sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = caption_model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = idxtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == STOP:\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RdC9ZO1-dmFSE8ftDy4Q0FMOBAjiBS6L"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40252,
     "status": "ok",
     "timestamp": 1574999280856,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "5apKpKSb4tnQ",
    "outputId": "5c99a3d2-60e1-4f5a-8508-c3e4d39fb67c"
   },
   "outputs": [],
   "source": [
    "for z in range(10):\n",
    "  pic = list(encoding_test.keys())[z]\n",
    "  image = encoding_test[pic].reshape((1,OUTPUT_DIM))\n",
    "  print(os.path.join(root_captioning,'Flicker8k_Dataset', pic))\n",
    "  x=plt.imread(os.path.join(root_captioning,'Flicker8k_Dataset', pic))\n",
    "  plt.imshow(x)\n",
    "  plt.show()\n",
    "  print(\"Caption:\",generateCaption(image))\n",
    "  print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQ3500HQ4yVN"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# urls = [\n",
    "#   \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/2015-03-09-phd-2nd-cluster-visit-1.png?raw=true\",\n",
    "#   \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/about-jeff-heaton-2018.jpg?raw=true\",\n",
    "#   \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/annie_dog.jpg?raw=true\",\n",
    "# ]\n",
    "\n",
    "# for url in urls:\n",
    "#   response = requests.get(url)\n",
    "#   img = Image.open(BytesIO(response.content))\n",
    "#   img.load()\n",
    "\n",
    "#   plt.imshow(img)\n",
    "#   plt.show()\n",
    "  \n",
    "#   response = requests.get(url)\n",
    "\n",
    "#   img = encodeImage(img).reshape((1,OUTPUT_DIM))\n",
    "#   print(img.shape)\n",
    "#   print(\"Caption:\",generateCaption(img))\n",
    "#   print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45759,
     "status": "ok",
     "timestamp": 1574999286374,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "oDMsl_HpMTbj",
    "outputId": "60d11bd9-f120-48c2-a7de-e1a80618ab8e"
   },
   "outputs": [],
   "source": [
    "urls = ['/content/gdrive/My Drive/Colab Notebooks/ew_resize_1920x1080.jpg']\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "  img = Image.open(url)\n",
    "  img.load()\n",
    "\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "\n",
    "  img = encodeImage(img).reshape((1,OUTPUT_DIM))\n",
    "  print(img.shape)\n",
    "  print(\"Caption:\",generateCaption(img))\n",
    "  print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6940,
     "status": "ok",
     "timestamp": 1574999880395,
     "user": {
      "displayName": "Ivan Christian",
      "photoUrl": "",
      "userId": "07036814873262838740"
     },
     "user_tz": -480
    },
    "id": "ku9DGIgbRzfb",
    "outputId": "1e10a6c0-ec52-4a99-a323-21922d3ff481"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "videoFile = \"/content/gdrive/My Drive/Colab Notebooks/scene1.mp4\"\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = '/content/gdrive/My Drive/Colab Notebooks/test_images/image' +  str(int(x)) + \".jpg\";x+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6bS9_ULTbLw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CDS Report.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
